networks:
  bigdata-net:
    driver: bridge

services:
  # ---------------------------------------------------------------------------
  # ZOOKEEPER
  # ---------------------------------------------------------------------------
  zookeeper:
    image: zookeeper:3.5
    container_name: zookeeper
    restart: always
    ports:
      - "2181:2181"
    volumes:
      - zookeeper_data:/data
      - zookeeper_datalog:/datalog
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # HADOOP HDFS (Storage)
  # ---------------------------------------------------------------------------
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - namenode_data:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    networks:
      - bigdata-net

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - datanode_data:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # HADOOP YARN (MapReduce - REQUIRED FOR PIG)
  # ---------------------------------------------------------------------------
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    ports:
      - "8088:8088"
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864
    networks:
      - bigdata-net

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      - SERVICE_PRECONDITION=namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088
    depends_on:
      - resourcemanager
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # HIVE
  # ---------------------------------------------------------------------------
  hive-metastore-postgresql:
    image: postgres:9.6
    container_name: hive-postgres
    restart: always
    environment:
      - POSTGRES_DB=metastore
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
    volumes:
      - hive_postgres_data:/var/lib/postgresql/data
    networks:
      - bigdata-net

  hive-metastore:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore
    restart: always
    environment:
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-postgres:5432/metastore
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive
      - HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hive
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
      - hive-metastore-postgresql
    networks:
      - bigdata-net

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    restart: always
    ports:
      - "10000:10000"
      - "10002:10002"
    environment:
      - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-postgres:5432/metastore
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
      - hive-metastore
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # SPARK
  # ---------------------------------------------------------------------------
  spark-master:
    image: bde2020/spark-master:3.0.0-hadoop3.2
    container_name: spark-master
    restart: always
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - namenode
    networks:
      - bigdata-net

  spark-worker:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: spark-worker
    restart: always
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    depends_on:
      - spark-master
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # HBASE
  # ---------------------------------------------------------------------------
  hbase-master:
    image: bde2020/hbase-master:1.0.0-hbase1.2.6
    container_name: hbase-master
    hostname: hbase-master
    restart: always
    ports:
      - "16010:16010"
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:9000/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_cluster_distributed=true
    depends_on:
      - namenode
      - zookeeper
    networks:
      - bigdata-net

  hbase-regionserver:
    image: bde2020/hbase-regionserver:1.0.0-hbase1.2.6
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    restart: always
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:9000/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_cluster_distributed=true
    depends_on:
      - hbase-master
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # CASSANDRA
  # ---------------------------------------------------------------------------
  cassandra:
    image: cassandra:4.0
    container_name: cassandra
    restart: always
    ports:
      - "9042:9042"
    environment:
      - CASSANDRA_CLUSTER_NAME=DevCluster
      - CASSANDRA_DC=datacenter1
      - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
      - MAX_HEAP_SIZE=512M
      - HEAP_NEWSIZE=100M
    volumes:
      - cassandra_data:/var/lib/cassandra
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # NEO4J
  # ---------------------------------------------------------------------------
  neo4j:
    image: neo4j:5.15-community
    container_name: neo4j
    restart: always
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      - NEO4J_AUTH=neo4j/password123
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=1G
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - bigdata-net

  # ---------------------------------------------------------------------------
  # PIG (Client Node)
  # ---------------------------------------------------------------------------
  pig:
    build:
      context: .
      dockerfile: pig.Dockerfile
    container_name: pig
    hostname: pig
    restart: always
    stdin_open: true
    tty: true
    environment:
      # These variables tell the base image how to configure the XML files
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
      - MAPRED_CONF_mapreduce_framework_name=yarn
    volumes:
      - pig_scripts:/pig/scripts
    depends_on:
      - namenode
      - resourcemanager
    networks:
      - bigdata-net

volumes:
  namenode_data:
  datanode_data:
  zookeeper_data:
  zookeeper_datalog:
  hive_postgres_data:
  cassandra_data:
  neo4j_data:
  neo4j_logs:
  pig_scripts:
